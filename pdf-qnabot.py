import os
import streamlit as st
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import ChatOpenAI
from PyPDF2 import PdfReader

# Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="RAG ê¸°ë°˜ Q&A ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ì„¤ì •")
pdfs = st.sidebar.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf", accept_multiple_files=True)

# ëª¨ë¸ ì„ íƒ ì˜µì…˜ ì¶”ê°€
model_option = st.sidebar.selectbox(
    "ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    ("gpt-4o-mini", "gpt-3.5-turbo")
)

temperature_option = st.sidebar.selectbox(
    "ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”",
    ("ì¼ê´€ì ì¸ (0)", "ê· í˜•ì¡íŒ (0.5)", "ì°½ì˜ì ì¸ (1)")
)

# temperature ê°’ ë§¤í•‘
temperature_mapping = {
    "ì¼ê´€ì ì¸ (0)": 0,
    "ê· í˜•ì¡íŒ (0.5)": 0.5,
    "ì°½ì˜ì ì¸ (1)": 1
}

# ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”"):
    st.session_state.qa_history = []
    st.sidebar.success("ëŒ€í™” ë‚´ì—­ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í™”ë©´ ì„¤ì •
st.title("RAG ê¸°ë°˜ Q&A ì±—ë´‡ğŸ¤–")
st.subheader("ì—…ë¡œë“œí•œ PDF ë¬¸ì„œğŸ“‹ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.")
st.markdown("â€» RAG(Retrieval Augmented Generation): ë‹µë³€ ì‹œ ë²¡í„°DBì—ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ì—¬ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê¸°ë²•")

# OpenAI API í‚¤ ì„¤ì •
openai_api_key = st.secrets["openai_api_key"]
os.environ["OPENAI_API_KEY"] = openai_api_key

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []
if "knowledge_base" not in st.session_state:
    st.session_state.knowledge_base = None

# PDF ì²˜ë¦¬ í•¨ìˆ˜
def process_pdfs(pdf_files):
    text = ""
    for pdf in pdf_files:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    embeddings = OpenAIEmbeddings()
    st.session_state.knowledge_base = FAISS.from_texts(chunks, embeddings)
    st.sidebar.success(f"{len(pdf_files)}ê°œì˜ PDFê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ê¸°ë³¸ PDF íŒŒì¼ ë¡œë“œ ë° ì²˜ë¦¬
def load_default_pdf():
    default_pdf_path = "data/default.pdf"
    if os.path.exists(default_pdf_path):
        with open(default_pdf_path, "rb") as pdf_file:
            process_pdfs([pdf_file])
        st.sidebar.info("ê¸°ë³¸ PDF íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        sst.sidebar.info("ì—…ë¡œë“œëœ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# PDF ì—…ë¡œë“œ ë˜ëŠ” ê¸°ë³¸ PDF ë¡œë“œ
if pdfs:
    process_pdfs(pdfs)
elif st.session_state.knowledge_base is None:
    load_default_pdf()

# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
st.write("---")
if st.session_state.knowledge_base is not None:
    user_question = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", height=100)
    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if user_question:
            docs = st.session_state.knowledge_base.similarity_search(user_question)
            
            # temperature ì„¤ì •
            temperature = temperature_mapping[temperature_option]
            
            # LLM ì„¤ì •
            llm = ChatOpenAI(model_name=model_option, temperature=temperature)
            
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_question)
            st.session_state.qa_history.append({"question": user_question, "answer": response})

    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for qa in reversed(st.session_state.qa_history):
        message_container = st.container()
        with message_container:
            col1, col2 = st.columns([1, 9])
            with col1:
                st.image("https://via.placeholder.com/40x40.png?text=You", width=40)
            with col2:
                st.markdown(f"**You:** {qa['question']}")
            
            col1, col2 = st.columns([1, 9])
            with col1:
                st.image("https://via.placeholder.com/40x40.png?text=Bot", width=40)
            with col2:
                st.markdown(f"**Bot:** {qa['answer']}")
        st.write("---")
else:
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ PDF íŒŒì¼ì´ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì„¤ì • í‘œì‹œ
st.sidebar.write(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {model_option}")
st.sidebar.write(f"í˜„ì¬ ì‘ë‹µ ìŠ¤íƒ€ì¼: {temperature_option}")
